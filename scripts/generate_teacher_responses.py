#!/usr/bin/env python
"""
Call GPT‑4 to produce teacher chain‑of‑thought and final yes/no answers.

This script takes as input a JSONL file containing StrategyQA questions and
student drafts (generated by `run_student_baseline.py`).  For each entry it
composes a prompt of the form described in the project plan【777585631172426†L23-L31】:

    Q: <original yes/no question>
    Student draft: <answer + clarifying questions>
    Teacher: Please think step‑by‑step and provide your thought process and final Yes/No answer.

The prompt is sent to OpenAI's GPT‑4 API to obtain the teacher’s chain of
thought and final answer.  Results are appended to each record as
`teacher_thought` and `teacher_answer`.  A dry‑run mode allows unit testing
without actually calling the API.

Example usage:

```
python generate_teacher_responses.py \
  --input_path data/student_drafts.jsonl \
  --output_path data/teacher_outputs.jsonl \
  --openai_api_key sk-... \
  --max_tokens 150
```
```

Notes:
* Real API calls can be expensive (~300k tokens total as estimated in the plan【777585631172426†L49-L52】), so you
  should set `--dry_run` when writing tests.
* This script prints progress to the console; you can safely terminate and
  resume processing by passing an offset via `--start_idx` if desired.
"""

import argparse
import json
import os
import re
from typing import Dict, Iterable

try:
    import openai  # type: ignore
except ImportError:
    openai = None  # type: ignore


def load_jsonl(path: str) -> Iterable[Dict[str, str]]:
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if line:
                try:
                    yield json.loads(line)
                except json.JSONDecodeError:
                    continue


def save_jsonl(records: Iterable[Dict[str, str]], path: str) -> None:
    dir_path = os.path.dirname(path)
    if dir_path:
        os.makedirs(dir_path, exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        for rec in records:
            f.write(json.dumps(rec, ensure_ascii=False) + "\n")


def extract_yes_no(text: str) -> str:
    """Extract a yes/no answer from the teacher’s response.

    We look for the first occurrence of 'yes' or 'no' (case‑insensitive) in
    the text.  If nothing is found, the full text is returned and the caller
    may handle it separately.
    """
    match = re.search(r"\b(yes|no)\b", text, re.IGNORECASE)
    if match:
        return match.group(1).capitalize()
    return text.strip()


def call_gpt4(prompt: str, api_key: str, max_tokens: int, temperature: float) -> str:
    """Send a prompt to GPT‑4 and return the response content.

    Args:
        prompt: The composed prompt string.
        api_key: Your OpenAI API key.
        max_tokens: Maximum tokens to generate in the response.
        temperature: Sampling temperature.

    Returns:
        The assistant’s message content.
    """
    if openai is None:
        raise ImportError("openai package is required for actual API calls.  Install it via pip.")
    openai.api_key = api_key
    response = openai.ChatCompletion.create(
        model="gpt-4",
        messages=[
            {
                "role": "system",
                "content": (
                    "You are an expert teacher providing chain-of-thought reasoning and final yes/no answers."
                ),
            },
            {"role": "user", "content": prompt},
        ],
        max_tokens=max_tokens,
        temperature=temperature,
    )
    return response["choices"][0]["message"]["content"].strip()


def main() -> None:
    parser = argparse.ArgumentParser(description="Generate teacher CoT and answers via GPT-4.")
    parser.add_argument("--input_path", type=str, required=True, help="Path to student drafts JSONL.")
    parser.add_argument("--output_path", type=str, required=True, help="Path to save teacher outputs JSONL.")
    parser.add_argument("--openai_api_key", type=str, default=None, help="OpenAI API key (omit when dry_run).")
    parser.add_argument("--max_tokens", type=int, default=150, help="Max tokens to generate for teacher response.")
    parser.add_argument("--temperature", type=float, default=0.3, help="Sampling temperature for GPT-4.")
    parser.add_argument("--dry_run", action="store_true", help="Do not call the API; generate dummy responses.")
    parser.add_argument(
        "--start_idx",
        type=int,
        default=0,
        help="Skip the first N records (useful for resuming interrupted runs).",
    )
    args = parser.parse_args()

    if not args.dry_run and not args.openai_api_key:
        raise ValueError("You must provide --openai_api_key when not in dry_run mode.")

    all_records = list(load_jsonl(args.input_path))
    output_records = []
    for idx, rec in enumerate(all_records):
        if idx < args.start_idx:
            continue
        question = rec.get("question") or rec.get("q") or ""
        student_draft = rec.get("student_draft", "")
        if not question or not student_draft:
            # Skip incomplete entries
            continue
        prompt = (
            f"Q: {question}\n"
            f"Student draft: {student_draft}\n"
            "Teacher: Please think step-by-step and provide your thought process and final Yes/No answer."
        )
        if args.dry_run:
            teacher_thought = (
                "[Dummy response] The Amazon River is in South America. The question asks whether it is in Peru."\
            )
            teacher_answer = "Yes"
        else:
            try:
                response_text = call_gpt4(
                    prompt,
                    api_key=args.openai_api_key,
                    max_tokens=args.max_tokens,
                    temperature=args.temperature,
                )
                teacher_thought = response_text
                teacher_answer = extract_yes_no(response_text)
            except Exception as e:
                # In case of API failure, store the exception message for debugging and continue
                teacher_thought = f"[Error] {e}"
                teacher_answer = ""
        new_rec = dict(rec)
        new_rec["teacher_thought"] = teacher_thought
        new_rec["teacher_answer"] = teacher_answer
        output_records.append(new_rec)
        # Print progress every 10 examples
        if (idx + 1) % 10 == 0:
            print(f"Processed {idx + 1}/{len(all_records)} questions")
    save_jsonl(output_records, args.output_path)
    print(f"Wrote {len(output_records)} teacher responses to {args.output_path}")


if __name__ == "__main__":
    main()